{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e23ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import arviz as az\n",
    "from theano import shared\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0ec4d-ea3e-4fd6-949d-3915e2d1bea2",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fccf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def normalize(x):\n",
    "    return x/np.sum(x)\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    return math.sqrt(np.mean((pred-actual)**2))\n",
    "\n",
    "def sort_category(unique, count,n):\n",
    "    output = np.ones(n) - 1\n",
    "    for i in range(n):\n",
    "        for j in range(len(unique)):\n",
    "            if(i==unique[j]):\n",
    "                output[i]=count[j]\n",
    "    return normalize(output) \n",
    "\n",
    "def perturb(x,noise=.001):\n",
    "    return tt.switch(tt.eq(x,1),1-noise, tt.switch(tt.eq(x,0), noise, x))\n",
    "\n",
    "def compute_ci_discrete(x, HDI, n, sim):\n",
    "    output = [None]*sim\n",
    "    for i in range(sim):\n",
    "        draw = np.random.choice(x, size = n, replace = True)\n",
    "        unique, counts = np.unique(draw, return_counts=True)\n",
    "        output[i] = sort_category(unique, counts,4)\n",
    "    lower = np.ones(len(output[0]))\n",
    "    upper = np.ones(len(output[0]))\n",
    "    output = np.transpose(output) # each element is now all the samples of one category\n",
    "    for i in range(len(output)):\n",
    "        lower[i] = np.quantile(output[i], q = (1-HDI)/2)\n",
    "        upper[i] = np.quantile(output[i], q = 1-(1-HDI)/2)\n",
    "    return [lower, upper]\n",
    "\n",
    "def compute_ci_continuous(x, HDI, n, sim):\n",
    "    output = np.ones(sim)\n",
    "    for i in range(sim):\n",
    "        draw = np.random.choice(x, size = n, replace = True)\n",
    "        output[i] = np.mean(draw)\n",
    "    lower = np.quantile(output, q = (1-HDI)/2)\n",
    "    upper = np.quantile(output, q = 1-(1-HDI)/2)\n",
    "    return [lower, upper]\n",
    "\n",
    "def computeA(m, s):\n",
    "    return (m*s)/(1-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52b8be-fbf9-4a25-a9c9-075383bc3d7a",
   "metadata": {},
   "source": [
    "# Computational models\n",
    "\n",
    "## I/O preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9900418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ecl_dat_multiple-outcome.csv', encoding=\"ISO-8859-1\")\n",
    "emotion = data.loc[data['condition'] == 'emotion']\n",
    "noemotion = data.loc[data['condition'] == 'no-emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d14d4-3077-48a9-b3a0-996eeca0736a",
   "metadata": {},
   "source": [
    "### Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062bb1b-ad56-4c7f-a1a3-6b8527f261a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_cause_purple_emotion_data = (np.array(emotion[\"relationBlueOne\"]) - 1) / 8.0\n",
    "human_cause_red_emotion_data = (np.array(emotion[\"relationBlueTwo\"]) - 1) / 8.0\n",
    "human_cause_purple_noemotion_data = (np.array(noemotion[\"relationBlueOne\"]) - 1) / 8.0\n",
    "human_cause_red_noemotion_data = (np.array(noemotion[\"relationBlueTwo\"]) - 1) / 8.0\n",
    "\n",
    "human_belief_purple_emotion_data = (np.array(emotion[\"expOne\"]) - 1) / 8.0\n",
    "human_belief_red_emotion_data = (np.array(emotion[\"expTwo\"]) - 1) / 8.0\n",
    "human_belief_purple_noemotion_data = (np.array(noemotion[\"expOne\"]) - 1) / 8.0\n",
    "human_belief_red_noemotion_data = (np.array(noemotion[\"expTwo\"]) - 1) / 8.0\n",
    "\n",
    "human_desire_purple_emotion_data = (np.array(emotion[\"intention3\"]) - 1) / 8.0\n",
    "human_desire_red_emotion_data = (np.array(emotion[\"intention4\"]) - 1) / 8.0\n",
    "human_desire_purple_noemotion_data = (np.array(noemotion[\"intention3\"]) - 1) / 8.0\n",
    "human_desire_red_noemotion_data = (np.array(noemotion[\"intention4\"]) - 1) / 8.0\n",
    "\n",
    "human_knowledge_emotion_data = (np.array(emotion[\"knowledge1\"]) - 1) / 8.0\n",
    "human_knowledge_noemotion_data = (np.array(noemotion[\"knowledge1\"]) - 1) / 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea327ae-e98a-4678-b3aa-b082faabdf83",
   "metadata": {},
   "source": [
    "### Means for causal, belief, desire, and knowledge inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786822e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_cause_purple_emotion = np.mean(human_cause_purple_emotion_data)\n",
    "human_cause_red_emotion = np.mean(human_cause_red_emotion_data)\n",
    "human_cause_purple_noemotion = np.mean(human_cause_purple_noemotion_data)\n",
    "human_cause_red_noemotion = np.mean(human_cause_red_noemotion_data)\n",
    "\n",
    "human_belief_purple_emotion = np.mean(human_belief_purple_emotion_data)\n",
    "human_belief_red_emotion = np.mean(human_belief_red_emotion_data )\n",
    "human_belief_purple_noemotion = np.mean(human_belief_purple_noemotion_data)\n",
    "human_belief_red_noemotion = np.mean(human_belief_red_noemotion_data)\n",
    "\n",
    "human_desire_purple_emotion = np.mean(human_desire_purple_emotion_data)\n",
    "human_desire_red_emotion = np.mean(human_desire_red_emotion_data)\n",
    "human_desire_purple_noemotion = np.mean(human_desire_purple_noemotion_data)\n",
    "human_desire_red_noemotion = np.mean(human_desire_red_noemotion_data)\n",
    "\n",
    "human_knowledge_emotion = np.mean(human_knowledge_emotion_data )\n",
    "human_knowledge_noemotion = np.mean(human_knowledge_noemotion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef97a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1948529411764706\n",
      "0.9154411764705882\n",
      "0.24107142857142858\n",
      "0.890625\n"
     ]
    }
   ],
   "source": [
    "print(human_cause_purple_emotion)\n",
    "print(human_cause_red_emotion)\n",
    "print(human_cause_purple_noemotion)\n",
    "print(human_cause_red_noemotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81446614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8014705882352942\n",
      "0.25183823529411764\n",
      "0.3236607142857143\n",
      "0.7879464285714286\n"
     ]
    }
   ],
   "source": [
    "print(human_belief_purple_emotion)\n",
    "print(human_belief_red_emotion)\n",
    "print(human_belief_purple_noemotion)\n",
    "print(human_belief_red_noemotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136d513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n",
      "0.2426470588235294\n",
      "0.8235294117647058\n",
      "0.2426470588235294\n"
     ]
    }
   ],
   "source": [
    "print(human_desire_purple_emotion)\n",
    "print(human_desire_red_emotion)\n",
    "print(human_desire_purple_emotion)\n",
    "print(human_desire_red_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d03075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6066176470588235\n",
      "0.7053571428571429\n"
     ]
    }
   ],
   "source": [
    "print(human_knowledge_emotion)\n",
    "print(human_knowledge_noemotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d59ce-d792-4479-b9d7-404a1371a795",
   "metadata": {},
   "source": [
    "## Model (for the condition with no emotional display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd853fd-501b-4689-b52b-f08278b5df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters are fixed across both conditions (emotions and no-emotions)\n",
    "# A noise parameter which controls how much randomness is added at each conditional sampling (e.g., drawing actions from belief and desire) was allowed to vary across both conditions\n",
    "\n",
    "# The model assumes that people perceive others to have a knowledgability of around 0.7.\n",
    "# We simulated this using a beta distribution with a = 5 and b = 2.\n",
    "a = 5\n",
    "b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2232f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f86f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">NUTS: [belief2_random, belief1_random, knowledge_p, knowledge_prior_p, world2, world1]\n",
      ">CompoundStep\n",
      ">>Metropolis: [knowledge]\n",
      ">>Metropolis: [knowledge_prior]\n",
      ">CategoricalGibbsMetropolis: [desire]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:12<00:00 Sampling 4 chains, 1,465 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 90 seconds.\n",
      "There were 256 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 390 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 346 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 473 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1279044231220166\n",
      "0.04374636815130617\n",
      "0.032031654683013444\n",
      "0.0905542953707098\n",
      "0.20988392857142854\n",
      "0.0014017857142857304\n",
      "0.008710725149271181\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model1:\n",
    "    world1 = pm.Beta(\"world1\", .1, .1, shape=(1)) # inference that the box causes the purple bulb to switch on; the U-shaped beta distribution reduces the chance of \"vague\" inferences\n",
    "    world2 = pm.Beta(\"world2\", .1, .1, shape=(1)) # inference that the box causes the red bulb to switch on\n",
    "    knowledge_prior_p = pm.Beta(\"knowledge_prior_p\", a, b, shape=(1))\n",
    "    knowledge_prior = pm.Binomial(\"knowledge_prior\", 1, knowledge_prior_p, shape=(1))\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1))\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Beta(\"belief1_random\", .1, .1, shape=(1)) # belief inference that the agent thinks that the box causes the purple bulb to switch on\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world1 + (1-knowledge)*belief1_random)\n",
    "    belief2_random = pm.Beta(\"belief2_random\", .1, .1, shape=(1)) # belief inference that the agent thinks that the box causes the red bulb to switch on\n",
    "    belief2 = pm.Deterministic(\"belief2\", knowledge*world2 + (1-knowledge)*belief2_random)\n",
    "    \n",
    "    desire = pm.Categorical(\"desire\", [5,5,1,1], shape=(1)) # purple, red, both, others\n",
    "    \n",
    "    action_others_p = .05 # low prior probability of push box action\n",
    "    action_p = pm.Deterministic(\"action_p\", belief1*tt.eq(desire,0) + \\ # if believe box -> purple and desire purple bulb to light up\n",
    "                                belief2*tt.eq(desire,1) + \\ # if believe box -> red and desire red bulb to light up\n",
    "                                belief1*belief2*tt.eq(desire,2) + \\ # if believe box -> both and desire both bulbs to light up\n",
    "                                action_others_p*tt.eq(desire,3) ) # if believe box -> other event and desire some other event to occur\n",
    "    action = pm.Binomial(\"action\", 1, action_p, observed = [1])\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", action*world1) # whether purple bulb lights up\n",
    "    outcome2_p = pm.Deterministic(\"outcome2_p\", action*world2) # whether red bulb lights up\n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = [0])\n",
    "    outcome2 = pm.Binomial(\"outcome2\", 1, outcome2_p, observed = [1])\n",
    "    \n",
    "    # agent is happy if the outcome is congruent with his desires\n",
    "    happy = outcome1*tt.eq(desire,0) + outcome2*tt.eq(desire,1) + outcome1*outcome2*tt.eq(desire,2)\n",
    "    # agent is frustrated if the outcome does not satisfy his desires\n",
    "    frustrated = tt.neq(outcome1,1)*tt.eq(desire,0)*tt.gt(belief1,.5) + tt.neq(outcome2,1)*tt.eq(desire,1)*tt.gt(belief2,.5) + tt.gt(belief1,.5)*tt.gt(belief2,.5)*tt.eq(desire,2)*tt.or_( tt.neq(outcome1,1), tt.neq(outcome2,1) )\n",
    "    neutral = [1]\n",
    "    emotion_array = tt.transpose(tt.stack(happy, frustrated, neutral))\n",
    "\n",
    "    expression = pm.Categorical(\"expression\",emotion_array,observed=[2] )\n",
    "    draw = 2000 \n",
    "    trace1 = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False) \n",
    "\n",
    "world1posterior = np.mean(trace1[\"world1\"].T[0])\n",
    "print(rmse(world1posterior, human_cause_purple_noemotion))\n",
    "world2posterior = np.mean(trace1[\"world2\"].T[0])\n",
    "print(rmse(world2posterior, human_cause_red_noemotion))\n",
    "\n",
    "belief1posterior = np.mean(trace1[\"belief1\"].T[0])\n",
    "print(rmse(belief1posterior, human_belief_purple_noemotion))\n",
    "belief2posterior = np.mean(trace1[\"belief2\"].T[0])\n",
    "print(rmse(belief2posterior, human_belief_red_noemotion))\n",
    "\n",
    "unique, counts = np.unique(trace1[\"desire\"], return_counts=True)\n",
    "desire_posterior = sort_category(unique, counts,n=4)\n",
    "desire1posterior = desire_posterior[0] + desire_posterior[2]/2\n",
    "print(rmse(desire1posterior,human_desire_purple_noemotion))\n",
    "desire2posterior = desire_posterior[1] + desire_posterior[2]/2\n",
    "print(rmse(desire2posterior,human_desire_red_noemotion))                            \n",
    "knowledge1posterior = np.mean(trace1[\"knowledge_p\"].T[0])\n",
    "print(rmse(knowledge1posterior, human_knowledge_noemotion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2bce4-00b7-4ac1-acbc-5bcd440dcd51",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12ba781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world1 posterior: 0.11316700544941195\n",
      "world2 posterior: 0.9343713681513062\n",
      "knowledge prior p: 0.71377282620844\n",
      "knowledge posterior p: 0.7140678680064141\n",
      "knowledge prior: 0.6985\n",
      "knowledge posterior: 0.714\n",
      "belief1: 0.29162905960270086\n",
      "belief2: 0.8785007239421384\n",
      "desire: {0: 1756, 1: 5857, 2: 237, 3: 150}\n",
      "[0.2195   0.732125 0.029625 0.01875 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"world1 posterior: \" + str(np.mean(trace1[\"world1\"])))\n",
    "print(\"world2 posterior: \" + str(np.mean(trace1[\"world2\"])))\n",
    "print(\"knowledge prior p: \" + str(np.mean(trace1[\"knowledge_prior_p\"])))\n",
    "print(\"knowledge posterior p: \" + str(np.mean(trace1[\"knowledge_p\"])))\n",
    "print(\"knowledge prior: \" + str(np.mean(trace1[\"knowledge_prior\"])))\n",
    "print(\"knowledge posterior: \" + str(np.mean(trace1[\"knowledge\"])))\n",
    "print(\"belief1: \" + str(np.mean(trace1[\"belief1\"])))\n",
    "print(\"belief2: \" + str(np.mean(trace1[\"belief2\"])))\n",
    "unique, counts = np.unique(trace1[\"desire\"], return_counts=True)\n",
    "print(\"desire: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cdeac-0de9-4227-9c22-ce8d468552da",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef915fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world1 :[0.06115659864161587, 0.1720956233790888]\n",
      "world2 :[0.8923007154207211, 0.9714265861532441]\n",
      "belief1 :[0.19336573419088857, 0.3930769737526257]\n",
      "belief2 :[0.7999782127405128, 0.9399937244146536]\n",
      "desire :[array([0.193   , 0.706   , 0.020975, 0.011   ]), array([0.245   , 0.760025, 0.041   , 0.028   ])]\n",
      "knowledge :[0.673375162642256, 0.7542611779781163]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world1 :\" + str(compute_ci_continuous(flatten(trace1[\"world1\"]), HDI = .95, n = 56, sim = 1000))) \n",
    "print(\"world2 :\" + str(compute_ci_continuous(flatten(trace1[\"world2\"]), HDI = .95, n = 56, sim = 1000))) \n",
    "print(\"belief1 :\" + str(compute_ci_continuous(flatten(trace1[\"belief1\"]), HDI = .95, n = 56, sim = 1000))) \n",
    "print(\"belief2 :\" + str(compute_ci_continuous(flatten(trace1[\"belief2\"]), HDI = .95, n = 56, sim = 1000))) \n",
    "print(\"desire :\" + str(compute_ci_discrete(flatten(trace1[\"desire\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"knowledge :\" + str(compute_ci_continuous(flatten(trace1[\"knowledge_p\"]), HDI = .95, n =56, sim = 1000))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609da00-2d7e-4102-b025-692d99fd7fbc",
   "metadata": {},
   "source": [
    "## Model (for the condition with emotional displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d436be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cad25c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">NUTS: [belief2_random, belief1_random, knowledge_p, knowledge_prior_p, world2, world1]\n",
      ">CompoundStep\n",
      ">>Metropolis: [knowledge]\n",
      ">>Metropolis: [knowledge_prior]\n",
      ">CategoricalGibbsMetropolis: [desire]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:23<00:00 Sampling 4 chains, 1,091 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 104 seconds.\n",
      "There were 225 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 248 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 194 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 424 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014511422543032476\n",
      "0.002368703327710442\n",
      "0.11550815865778352\n",
      "0.33959917952104945\n",
      "0.12478308823529416\n",
      "0.1909595588235294\n",
      "0.0372422143465746\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model2:\n",
    "    world1 = pm.Beta(\"world1\", .1, .1, shape=(1)) # inference that the box causes the purple bulb to switch on; the U-shaped beta distribution reduces the chance of \"vague\" inferences\n",
    "    world2 = pm.Beta(\"world2\", .1, .1, shape=(1)) # inference that the box causes the red bulb to switch on\n",
    "    knowledge_prior_p = pm.Beta(\"knowledge_prior_p\", 5, 2, shape=(1))\n",
    "    knowledge_prior = pm.Binomial(\"knowledge_prior\", 1, knowledge_prior_p, shape=(1))\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", 5, 2, shape=(1))\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Beta(\"belief1_random\", .1, .1, shape=(1)) # belief inference that the agent thinks that the box causes the purple bulb to switch on\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world1 + (1-knowledge)*belief1_random)\n",
    "    belief2_random = pm.Beta(\"belief2_random\", .1, .1, shape=(1)) # belief inference that the agent thinks that the box causes the red bulb to switch on\n",
    "    belief2 = pm.Deterministic(\"belief2\", knowledge*world2 + (1-knowledge)*belief2_random)\n",
    "    \n",
    "    desire = pm.Categorical(\"desire\", [5,5,1,1], shape=(1)) # purple, red, both, others\n",
    "    \n",
    "    action_others_p = .05 # low prior probability of push box action\n",
    "    action_p = pm.Deterministic(\"action_p\", belief1*tt.eq(desire,0) + \\ # if believe box -> purple and desire purple bulb to light up\n",
    "                                belief2*tt.eq(desire,1) + \\ # if believe box -> red and desire red bulb to light up\n",
    "                                belief1*belief2*tt.eq(desire,2) + \\ # if believe box -> both and desire both bulbs to light up\n",
    "                                action_others_p*tt.eq(desire,3) ) # if believe box -> other event and desire some other event to occur\n",
    "    action = pm.Binomial(\"action\", 1, action_p, observed = [1])\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", action*world1) # whether purple bulb lights up\n",
    "    outcome2_p = pm.Deterministic(\"outcome2_p\", action*world2) # whether red bulb lights up\n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = [0])\n",
    "    outcome2 = pm.Binomial(\"outcome2\", 1, outcome2_p, observed = [1])\n",
    "    \n",
    "    # agent is happy if the outcome is congruent with his desires\n",
    "    happy = outcome1*tt.eq(desire,0) + outcome2*tt.eq(desire,1) + outcome1*outcome2*tt.eq(desire,2) \n",
    "    # agent is frustrated if the outcome does not satisfy his desires\n",
    "    frustrated = tt.neq(outcome1,1)*tt.eq(desire,0)*tt.gt(belief1,.5) + tt.neq(outcome2,1)*tt.eq(desire,1)*tt.gt(belief2,.5) + tt.gt(belief1,.5)*tt.gt(belief2,.5)*tt.eq(desire,2)*tt.or_( tt.neq(outcome1,1), tt.neq(outcome2,1) )\n",
    "    neutral = [1]\n",
    "    emotion_array = tt.transpose(tt.stack(perturb(happy), perturb(frustrated), perturb(neutral)))\n",
    "    \n",
    "    expression = pm.Categorical(\"expression\",emotion_array,observed=[1] )\n",
    "    draw = 2000 \n",
    "    trace2 = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False) \n",
    "\n",
    "world1posterior = np.mean(trace2[\"world1\"].T[0])\n",
    "print(rmse(world1posterior, human_cause_purple_emotion))\n",
    "world2posterior = np.mean(trace2[\"world2\"].T[0])\n",
    "print(rmse(world2posterior, human_cause_red_emotion))\n",
    "\n",
    "belief1posterior = np.mean(trace2[\"belief1\"].T[0])\n",
    "print(rmse(belief1posterior, human_belief_purple_emotion))\n",
    "belief2posterior = np.mean(trace2[\"belief2\"].T[0])\n",
    "print(rmse(belief2posterior, human_belief_red_emotion))\n",
    "\n",
    "unique, counts = np.unique(trace2[\"desire\"], return_counts=True)\n",
    "desire_posterior = sort_category(unique, counts,n=4)\n",
    "desire1posterior = desire_posterior[0] + desire_posterior[2]/2\n",
    "print(rmse(desire1posterior,human_desire_purple_emotion))\n",
    "desire2posterior = desire_posterior[1] + desire_posterior[2]/2\n",
    "print(rmse(desire2posterior,human_desire_red_emotion))                            \n",
    "knowledge1posterior = np.mean(trace2[\"knowledge_p\"].T[0])\n",
    "print(rmse(knowledge1posterior, human_knowledge_emotion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8b5e9-1a31-4a1e-9a66-ab69d805f0ed",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d99f6155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world1 posterior: 0.1803415186334381\n",
      "world2 posterior: 0.9178098797982986\n",
      "knowledge prior p: 0.7182046625988633\n",
      "knowledge posterior p: 0.6438598614053981\n",
      "knowledge prior: 0.735375\n",
      "knowledge posterior: 0.15675\n",
      "belief1: 0.9169787468930777\n",
      "belief2: 0.5914374148151671\n",
      "desire: {0: 7188, 1: 15, 2: 797}\n",
      "[0.8985   0.001875 0.099625 0.      ]\n"
     ]
    }
   ],
   "source": [
    "print(\"world1 posterior: \" + str(np.mean(trace2[\"world1\"])))\n",
    "print(\"world2 posterior: \" + str(np.mean(trace2[\"world2\"])))\n",
    "print(\"knowledge prior p: \" + str(np.mean(trace2[\"knowledge_prior_p\"])))\n",
    "print(\"knowledge posterior p: \" + str(np.mean(trace2[\"knowledge_p\"])))\n",
    "print(\"knowledge prior: \" + str(np.mean(trace2[\"knowledge_prior\"])))\n",
    "print(\"knowledge posterior: \" + str(np.mean(trace2[\"knowledge\"])))\n",
    "print(\"belief1: \" + str(np.mean(trace2[\"belief1\"])))\n",
    "print(\"belief2: \" + str(np.mean(trace2[\"belief2\"])))\n",
    "unique, counts = np.unique(trace2[\"desire\"], return_counts=True)\n",
    "print(\"desire: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a10b6-3cd4-4f70-b4a0-e600d362df1d",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42cd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world1 :[0.11748851925940453, 0.24865624970756112]\n",
      "world2 :[0.8703572237077039, 0.9596766221292115]\n",
      "belief1 :[0.8827354270268029, 0.9467683325793091]\n",
      "belief2 :[0.48780842200607044, 0.6938234913162087]\n",
      "desire :[array([0.879, 0.   , 0.081, 0.   ]), array([0.917, 0.005, 0.119, 0.   ])]\n",
      "knowledge :[0.6046379468896996, 0.684843689631173]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world1 :\" + str(compute_ci_continuous(flatten(trace2[\"world1\"]), HDI = .95, n = 68, sim = 1000))) \n",
    "print(\"world2 :\" + str(compute_ci_continuous(flatten(trace2[\"world2\"]), HDI = .95, n = 68, sim = 1000))) \n",
    "print(\"belief1 :\" + str(compute_ci_continuous(flatten(trace2[\"belief1\"]), HDI = .95, n = 68, sim = 1000))) \n",
    "print(\"belief2 :\" + str(compute_ci_continuous(flatten(trace2[\"belief2\"]), HDI = .95, n = 68, sim = 1000))) \n",
    "print(\"desire :\" + str(compute_ci_discrete(flatten(trace2[\"desire\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"knowledge :\" + str(compute_ci_continuous(flatten(trace2[\"knowledge_p\"]), HDI = .95, n = 68, sim = 1000))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
