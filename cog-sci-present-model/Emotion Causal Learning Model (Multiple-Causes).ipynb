{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e23ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "from theano import shared\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90127178-a406-45fb-b8a3-e6dbbeea8ae5",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def normalize(x):\n",
    "    return x/np.sum(x)\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    return math.sqrt(np.mean((pred-actual)**2))\n",
    "\n",
    "def sort_category(unique, count):\n",
    "    output = np.ones(3) - 1\n",
    "    for i in range(3):\n",
    "        for j in range(len(unique)):\n",
    "            if(i==unique[j]):\n",
    "                output[i]=count[j]\n",
    "    return normalize(output) \n",
    "\n",
    "def perturb(x, noise=.001):\n",
    "    return tt.switch(tt.ge(x,1),1-noise, tt.switch(tt.le(x,0), noise, x))\n",
    "\n",
    "def compute_ci_discrete(x, HDI, n, sim):\n",
    "    output = [None]*sim\n",
    "    for i in range(sim):\n",
    "        draw = np.random.choice(x, size = n, replace = True)\n",
    "        unique, counts = np.unique(draw, return_counts=True)\n",
    "        output[i] = sort_category(unique, counts)\n",
    "    lower = np.ones(len(output[0]))\n",
    "    upper = np.ones(len(output[0]))\n",
    "    output = np.transpose(output) # each element is now all the samples of one category\n",
    "    for i in range(len(output)):\n",
    "        lower[i] = np.quantile(output[i], q = (1-HDI)/2)\n",
    "        upper[i] = np.quantile(output[i], q = 1-(1-HDI)/2)\n",
    "    return [lower, upper]\n",
    "\n",
    "def compute_ci_continuous(x, HDI, n, sim):\n",
    "    output = np.ones(sim)\n",
    "    for i in range(sim):\n",
    "        draw = np.random.choice(x, size = n, replace = True)\n",
    "        output[i] = np.mean(draw)\n",
    "    lower = np.quantile(output, q = (1-HDI)/2)\n",
    "    upper = np.quantile(output, q = 1-(1-HDI)/2)\n",
    "    return [lower, upper]\n",
    "\n",
    "def computeA(m, s):\n",
    "    return (m*s)/(1-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa8274-cc41-472f-bee2-5447e15856c4",
   "metadata": {},
   "source": [
    "# Computational models for mutiple-causes scenario\n",
    "\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../cog-sci-present-analysis/multiple-causes-scenario/ecl_dat.csv', encoding=\"ISO-8859-1\")\n",
    "emotion = data.loc[data['condition'] == 'condition 1']\n",
    "noemotion = data.loc[data['condition'] == 'condition 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85c6ad-d646-432e-bbf5-0dd2b1da64f4",
   "metadata": {},
   "source": [
    "### Computing means for causal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion = np.array(emotion[\"relationBlueNorm\"])\n",
    "world2human_emotion = np.array(emotion[\"relationOrangeNorm\"])\n",
    "world3human_emotion = np.array(emotion[\"relationOrangeBlueNorm\"])\n",
    "worldhuman_emotion = sort_category([0,1,2],[np.mean(world1human_emotion),np.mean(world2human_emotion),np.mean(world3human_emotion)])\n",
    "\n",
    "world1human_noemotion = np.array(noemotion[\"relationBlueNorm\"]) \n",
    "world2human_noemotion = np.array(noemotion[\"relationOrangeNorm\"]) \n",
    "world3human_noemotion = np.array(noemotion[\"relationOrangeBlueNorm\"])\n",
    "worldhuman_noemotion = sort_category([0,1,2],[np.mean(world1human_noemotion),np.mean(world2human_noemotion),np.mean(world3human_noemotion)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fc256-edff-49f9-a924-691835b117b1",
   "metadata": {},
   "source": [
    "### Computing means for belief inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief1human_emotion = np.array(emotion[\"expBlueNorm\"]) \n",
    "belief2human_emotion = np.array(emotion[\"expOrangeNorm\"]) \n",
    "belief3human_emotion = np.array(emotion[\"expBothNorm\"]) \n",
    "beliefhuman_emotion = sort_category([0,1,2],[np.mean(belief1human_emotion),np.mean(belief2human_emotion),np.mean(belief3human_emotion)])\n",
    "\n",
    "belief1human_noemotion = np.array(noemotion[\"expBlueNorm\"]) \n",
    "belief2human_noemotion = np.array(noemotion[\"expOrangeNorm\"]) \n",
    "belief3human_noemotion = np.array(noemotion[\"expBothNorm\"]) \n",
    "beliefhuman_noemotion = sort_category([0,1,2],[np.mean(belief1human_noemotion),np.mean(belief2human_noemotion),np.mean(belief3human_noemotion)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fe87d-81de-4a09-be67-74edec134b7c",
   "metadata": {},
   "source": [
    "### Computing means for knowledge and desire inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgehuman_emotion = (np.array(emotion[\"knowledge1\"])-1)/8\n",
    "desirehuman_emotion = (np.array(emotion[\"desire\"])-1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f474567",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgehuman_noemotion = (np.array(noemotion[\"knowledge1\"])-1)/8\n",
    "desirehuman_noemotion = (np.array(noemotion[\"desire\"])-1)/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b61dfd-6178-4b1d-9c8f-0be11bf8457f",
   "metadata": {},
   "source": [
    "## Model (for the condition with no emotional display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters are fixed across both conditions (emotions and no-emotions)\n",
    "# A noise parameter which controls how much randomness is added at each conditional sampling (e.g., drawing actions from belief and desire) was allowed to vary across both conditions\n",
    "\n",
    "# The model assumes that people perceive others to have high knowledgability.\n",
    "# We simulated this using a beta distribution with a = 5 and b = 2 (mean of .71).\n",
    "a = 5\n",
    "b = 2\n",
    "\n",
    "d = .5 # fixed prior for desire\n",
    "delay = .2 # probability that first action had a delayed effect\n",
    "human_prior = [0.3816152,0.3063088,0.3120760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model1:\n",
    "    # the noise parameter affects the amount of randomness included into the sampling process. \n",
    "    # For example, a person's actions might sometimes be incongruent to his intentions and event relationships can be noisy\n",
    "    # we set a higher noise parameter for the no-emotion condition as this led to slightly better model fit\n",
    "    # however, even when we fixed the noise for both models, the overall inference patterns remained qualitatively similar\n",
    "    noise = .25\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1)) # blue, orange, both\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # desire bulb to turn on=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p) # perturb ensures that the probability is not equals to 1 or 0\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if believe both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p) # perturb ensures that the probability is not equals to 1 or 0\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will likely not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome when probability is 1 or 0\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they likely won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=2 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_blue_p = pm.Deterministic(\"action2_blue_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,0)*(1-noise) + \\\n",
    "                                                                  # if believe both are needed and orange was pushed previously, then push blue\n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,1)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,1)*noise,\n",
    "                                                                  # if outcome was reached at t1, no further action required\n",
    "                                                                  noise)) \n",
    "    action2_blue_p = perturb(action2_blue_p)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_orange_p = pm.Deterministic(\"action2_orange_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,1)*(1-noise) + \\\n",
    "                                                                  # if believe both are needed and blue was pushed previously, then push orange \n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,0)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,0)*noise,\n",
    "                                                                  noise)) \n",
    "    action2_orange_p = perturb(action2_orange_p)\n",
    "    action2_stack = tt.transpose(tt.stack(action2_blue_p, action2_orange_p, [noise*2]))\n",
    "    action2 = pm.Categorical(\"action2\", action2_stack, observed=1, shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome2_p = pm.Deterministic(\"outcome2_p\", tt.eq(world,0)*tt.eq(action2,0) + \\\n",
    "                                  # if previous action has a delayed effect\n",
    "                                  tt.eq(world,0)*tt.eq(action1,0)*tt.neq(action2,0)*delay + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action2,1) + \\\n",
    "                                  # if previous action has a delayed effect\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*tt.neq(action2,1)*delay + \\\n",
    "                                  tt.eq(world,2)*tt.eq(action1,0)*tt.eq(action2,1)+ \\\n",
    "                                  tt.eq(world,2)*tt.eq(action1,1)*tt.eq(action2,0)) \n",
    "    outcome2_p = perturb(outcome2_p, noise)\n",
    "    outcome2 = pm.Binomial(\"outcome2\", 1, outcome2_p, observed = 1, shape = (1))\n",
    "    \n",
    "    happy2 = outcome2*desire*(1-noise) + noise*(1-desire)\n",
    "    frustrated2 = (1-outcome2)*desire*(1-noise) + noise*(1-desire)\n",
    "    neutral2 = [1]\n",
    "    emotion_array2 = tt.transpose(tt.stack(happy2, frustrated2, neutral2 ))\n",
    "    expression2 = pm.Categorical(\"expression2\",emotion_array2,observed=2 ) # happy, frustrated, neutral\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace1 = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "    \n",
    "# note: we compute the RMSE for reference (also useful to compare between models)\n",
    "# Conceptually, however, it might be difficult to compare these predictions one-to-one as normalized human ratings is not the same as probability\n",
    "unique, counts = np.unique(trace1[\"world\"], return_counts=True)\n",
    "worldposterior = sort_category(unique, counts)\n",
    "world_rmse = rmse(worldposterior, worldhuman_noemotion)\n",
    "print(world_rmse)\n",
    "unique, counts = np.unique(trace1[\"belief1\"], return_counts=True)\n",
    "belief1posterior = sort_category(unique, counts)\n",
    "belief_rmse = rmse(belief1posterior, beliefhuman_noemotion)\n",
    "print(belief_rmse)\n",
    "desireposterior = np.mean(trace1[\"desire\"])\n",
    "desire_rmse = rmse(desireposterior, desirehuman_noemotion)\n",
    "print(desire_rmse)\n",
    "knowledge_posterior = np.mean(trace1[\"knowledge\"])\n",
    "knowledge_rmse = rmse(knowledgeposterior, knowledgehuman_noemotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc4a22-758b-402d-9684-3056a981d00c",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ba781",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1[\"world\"], return_counts=True)\n",
    "print(\"world: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))\n",
    "\n",
    "print(\"knowledge p: \" + str(np.mean(trace1[\"knowledge_p\"])))\n",
    "unique, counts = np.unique(trace1[\"knowledge\"], return_counts=True)\n",
    "print(\"knowledge: \" + str(np.mean(trace1[\"knowledge\"])))\n",
    "\n",
    "unique, counts = np.unique(trace1[\"belief1\"], return_counts=True)\n",
    "print(\"belief1: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))\n",
    "\n",
    "unique, counts = np.unique(trace1[\"belief2\"], return_counts=True)\n",
    "print(\"belief2: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))\n",
    "\n",
    "unique, counts = np.unique(trace1[\"desire\"], return_counts=True)\n",
    "print(\"desire: \" + str(np.mean(trace1[\"desire\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afbe9e-3a5d-42c2-91a0-5240c134278c",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60350cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world :\" + str(compute_ci_discrete(flatten(trace1[\"world\"]), HDI = .95, n = 1000, sim = 1000))) #70\n",
    "print(\"knowledge :\" + str(compute_ci_continuous(flatten(trace1[\"knowledge_p\"]), HDI = .95, n = 70, sim = 1000)))\n",
    "print(\"belief1 :\" + str(compute_ci_discrete(flatten(trace1[\"belief1\"]), HDI = .95, n =1000, sim = 1000)))\n",
    "print(\"belief2 :\" + str(compute_ci_discrete(flatten(trace1[\"belief2\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"desire :\" + str(compute_ci_continuous(flatten(trace1[\"desire\"]), HDI = .95, n = 70, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f9e4a-8523-4915-9581-bfb8ff9379dc",
   "metadata": {},
   "source": [
    "## Model (for the condition with emotional displays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model2:\n",
    "    noise = .15\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # desire bulb to turn on=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p) # perturb ensures that the probability is not equals to 1 or 0\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if believe both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p) # perturb ensures that the probability is not equals to 1 or 0\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will likely not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=1 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_blue_p = pm.Deterministic(\"action2_blue_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,0)*(1-noise) + \\\n",
    "                                                                  # if belief both are needed and orange was pushed previously, then push blue\n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,1)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,1)*noise,\n",
    "                                                                  # if outcome was reached at t1, no further action required\n",
    "                                                                  noise)) \n",
    "    action2_blue_p = perturb(action2_blue_p)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_orange_p = pm.Deterministic(\"action2_orange_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,1)*(1-noise) + \\\n",
    "                                                                  # if believe both are needed and blue was pushed previously, then push orange \n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,0)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,0)*noise,\n",
    "                                                                  noise)) \n",
    "    action2_orange_p = perturb(action2_orange_p)\n",
    "    action2_stack = tt.transpose(tt.stack(action2_blue_p, action2_orange_p, [noise*2]))\n",
    "    action2 = pm.Categorical(\"action2\", action2_stack, observed=1, shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome2_p = pm.Deterministic(\"outcome2_p\", tt.eq(world,0)*tt.eq(action2,0) + \\\n",
    "                                  # if previous action has a delayed effect\n",
    "                                  tt.eq(world,0)*tt.eq(action1,0)*tt.neq(action2,0)*delay + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action2,1)+ \\\n",
    "                                  # if previous action has a delayed effect\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*tt.neq(action2,1)*delay + \\\n",
    "                                  tt.eq(world,2)*tt.eq(action1,0)*tt.eq(action2,1)+ \\\n",
    "                                  tt.eq(world,2)*tt.eq(action1,1)*tt.eq(action2,0)) \n",
    "    outcome2_p = perturb(outcome2_p, noise)\n",
    "    outcome2 = pm.Binomial(\"outcome2\", 1, outcome2_p, observed = 1, shape = (1))\n",
    "    \n",
    "    happy2 = outcome2*desire*(1-noise) + noise*(1-desire)\n",
    "    frustrated2 = (1-outcome2)*desire*(1-noise) + noise*(1-desire)\n",
    "    neutral2 = [1]\n",
    "    emotion_array2 = tt.transpose(tt.stack(happy2, frustrated2, neutral2 ))\n",
    "    expression2 = pm.Categorical(\"expression2\",emotion_array2,observed=0 ) # happy, frustrated, neutral\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace2 = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "# note: we compute the RMSE for reference (also useful to compare between models)\n",
    "# Conceptually, however, it might be difficult to compare these predictions one-to-one as normalized human ratings is not the same as probability\n",
    "unique, counts = np.unique(trace2[\"world\"], return_counts=True)\n",
    "worldposterior = sort_category(unique, counts)\n",
    "world_rmse = rmse(worldposterior, worldhuman_emotion)\n",
    "print(world_rmse)\n",
    "unique, counts = np.unique(trace2[\"belief1\"], return_counts=True)\n",
    "belief1posterior = sort_category(unique, counts)\n",
    "belief_rmse = rmse(belief1posterior, beliefhuman_emotion)\n",
    "print(belief_rmse)\n",
    "desireposterior = np.mean(trace2[\"desire\"])\n",
    "desire_rmse = rmse(desireposterior, desirehuman_emotion)\n",
    "print(desire_rmse)\n",
    "knowledge_posterior = np.mean(trace2[\"knowledge\"])\n",
    "knowledge_rmse = rmse(knowledgeposterior, knowledgehuman_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee55dfd-02d1-4ee1-a5b0-babd916359c9",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2[\"world\"], return_counts=True)\n",
    "print(\"world: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique,counts))\n",
    "print(\"knowledge p: \" + str(np.mean(trace2[\"knowledge_p\"])))\n",
    "print(\"knowledge: \" + str(np.mean(trace2[\"knowledge\"])))\n",
    "unique, counts = np.unique(trace2[\"belief1\"], return_counts=True)\n",
    "print(\"belief1: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique,counts))\n",
    "unique, counts = np.unique(trace2[\"belief2\"], return_counts=True)\n",
    "print(\"belief2: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique,counts))\n",
    "unique, counts = np.unique(trace2[\"desire\"], return_counts=True)\n",
    "print(\"desire: \" + str(np.mean(trace2[\"desire\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e3264-dc44-45da-94b5-9c2f82a39106",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world :\" + str(compute_ci_discrete(flatten(trace2[\"world\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"knowledge :\" + str(compute_ci_continuous(flatten(trace2[\"knowledge_p\"]), HDI = .95, n = 59, sim = 1000)))\n",
    "print(\"belief1 :\" + str(compute_ci_discrete(flatten(trace2[\"belief1\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"belief2 :\" + str(compute_ci_discrete(flatten(trace2[\"belief2\"]), HDI = .95, n = 1000, sim = 1000)))\n",
    "print(\"desire :\" + str(compute_ci_continuous(flatten(trace2[\"desire\"]), HDI = .95, n = 59, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c310b5b",
   "metadata": {},
   "source": [
    "# Computational models for tracking study\n",
    "\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c301ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_data = pd.read_csv('../cog-sci-present-analysis/multiple-causes-scenario-tracking/ecl_dat.csv', encoding=\"ISO-8859-1\")\n",
    "emotion_track = tracking_data.loc[tracking_data['condition'] == 'condition 1']\n",
    "noemotion_track = tracking_data.loc[tracking_data['condition'] == 'condition 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5817a65-b465-45de-a439-499a87055747",
   "metadata": {},
   "source": [
    "### Computing means for causal inference (at various snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion_t1 = np.array(emotion_track[\"relation1BlueNorm\"])\n",
    "world2human_emotion_t1 = np.array(emotion_track[\"relation1OrangeNorm\"])\n",
    "world3human_emotion_t1 = np.array(emotion_track[\"relation1OrangeBlueNorm\"])\n",
    "worldhuman_emotion_t1 = sort_category([0,1,2],[np.mean(world1human_emotion_t1),np.mean(world2human_emotion_t1),np.mean(world3human_emotion_t1)])\n",
    "\n",
    "world1human_noemotion_t1 = np.array(noemotion_track[\"relation1BlueNorm\"]) \n",
    "world2human_noemotion_t1 = np.array(noemotion_track[\"relation1OrangeNorm\"]) \n",
    "world3human_noemotion_t1 = np.array(noemotion_track[\"relation1OrangeBlueNorm\"])\n",
    "worldhuman_noemotion_t1 = sort_category([0,1,2],[np.mean(world1human_noemotion_t1),np.mean(world2human_noemotion_t1),np.mean(world3human_noemotion_t1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion_t2 = np.array(emotion_track[\"relation2BlueNorm\"])\n",
    "world2human_emotion_t2 = np.array(emotion_track[\"relation2OrangeNorm\"])\n",
    "world3human_emotion_t2 = np.array(emotion_track[\"relation2OrangeBlueNorm\"])\n",
    "worldhuman_emotion_t2 = sort_category([0,1,2],[np.mean(world1human_emotion_t2),np.mean(world2human_emotion_t2),np.mean(world3human_emotion_t2)])\n",
    "\n",
    "world1human_noemotion_t2 = np.array(noemotion_track[\"relation2BlueNorm\"]) \n",
    "world2human_noemotion_t2 = np.array(noemotion_track[\"relation2OrangeNorm\"]) \n",
    "world3human_noemotion_t2 = np.array(noemotion_track[\"relation2OrangeBlueNorm\"])\n",
    "worldhuman_noemotion_t2 = sort_category([0,1,2],[np.mean(world1human_noemotion_t2),np.mean(world2human_noemotion_t2),np.mean(world3human_noemotion_t2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion_t3 = np.array(emotion_track[\"relation3BlueNorm\"])\n",
    "world2human_emotion_t3 = np.array(emotion_track[\"relation3OrangeNorm\"])\n",
    "world3human_emotion_t3 = np.array(emotion_track[\"relation3OrangeBlueNorm\"])\n",
    "worldhuman_emotion_t3 = sort_category([0,1,2],[np.mean(world1human_emotion_t3),np.mean(world2human_emotion_t3),np.mean(world3human_emotion_t3)])\n",
    "\n",
    "world1human_noemotion_t3 = np.array(noemotion_track[\"relation3BlueNorm\"]) \n",
    "world2human_noemotion_t3 = np.array(noemotion_track[\"relation3OrangeNorm\"]) \n",
    "world3human_noemotion_t3 = np.array(noemotion_track[\"relation3OrangeBlueNorm\"])\n",
    "worldhuman_noemotion_t3 = sort_category([0,1,2],[np.mean(world1human_noemotion_t3),np.mean(world2human_noemotion_t3),np.mean(world3human_noemotion_t3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9581a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion_t4 = np.array(emotion_track[\"relation4BlueNorm\"])\n",
    "world2human_emotion_t4 = np.array(emotion_track[\"relation4OrangeNorm\"])\n",
    "world3human_emotion_t4 = np.array(emotion_track[\"relation4OrangeBlueNorm\"])\n",
    "worldhuman_emotion_t4 = sort_category([0,1,2],[np.mean(world1human_emotion_t4),np.mean(world2human_emotion_t4),np.mean(world3human_emotion_t4)])\n",
    "\n",
    "world1human_noemotion_t4 = np.array(noemotion_track[\"relation4BlueNorm\"]) \n",
    "world2human_noemotion_t4 = np.array(noemotion_track[\"relation4OrangeNorm\"]) \n",
    "world3human_noemotion_t4 = np.array(noemotion_track[\"relation4OrangeBlueNorm\"])\n",
    "worldhuman_noemotion_t4 = sort_category([0,1,2],[np.mean(world1human_noemotion_t4),np.mean(world2human_noemotion_t4),np.mean(world3human_noemotion_t4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "world1human_emotion_t5 = np.array(emotion_track[\"relation5BlueNorm\"])\n",
    "world2human_emotion_t5 = np.array(emotion_track[\"relation5OrangeNorm\"])\n",
    "world3human_emotion_t5 = np.array(emotion_track[\"relation5OrangeBlueNorm\"])\n",
    "worldhuman_emotion_t5 = sort_category([0,1,2],[np.mean(world1human_emotion_t5),np.mean(world2human_emotion_t5),np.mean(world3human_emotion_t5)])\n",
    "\n",
    "world1human_noemotion_t5 = np.array(noemotion_track[\"relation5BlueNorm\"]) \n",
    "world2human_noemotion_t5 = np.array(noemotion_track[\"relation5OrangeNorm\"]) \n",
    "world3human_noemotion_t5 = np.array(noemotion_track[\"relation5OrangeBlueNorm\"])\n",
    "worldhuman_noemotion_t5 = sort_category([0,1,2],[np.mean(world1human_noemotion_t5),np.mean(world2human_noemotion_t5),np.mean(world3human_noemotion_t5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa929a",
   "metadata": {},
   "source": [
    "## Models (for the condition with no emotional display) across various snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model1ab:\n",
    "    noise = .25\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    world_prior = pm.Categorical(\"world_prior\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace1ab = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "unique, counts = np.unique(trace1ab[\"world_prior\"], return_counts=True)\n",
    "worldposterior_t1 = sort_category(unique, counts)\n",
    "rmse_output_t1 = rmse(worldposterior_t1, worldhuman_noemotion_t1)\n",
    "print(rmse_output_t1)\n",
    "unique, counts = np.unique(trace1ab[\"world\"], return_counts=True)\n",
    "worldposterior_t2 = sort_category(unique, counts)\n",
    "rmse_output_t2 = rmse(worldposterior_t2, worldhuman_noemotion_t2)\n",
    "print(rmse_output_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model1c:\n",
    "    noise = .25\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=2 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace1c = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "unique, counts = np.unique(trace1c[\"world\"], return_counts=True)\n",
    "worldposterior_t3 = sort_category(unique, counts)\n",
    "rmse_output_t3 = rmse(worldposterior_t3, worldhuman_noemotion_t3)\n",
    "print(rmse_output_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ee567",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model1d:\n",
    "    noise = .25\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=2 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_blue_p = pm.Deterministic(\"action2_blue_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,0)*(1-noise) + \\\n",
    "                                                                  # if belief both are needed and orange was pushed previously, then push blue\n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,1)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,1)*noise,\n",
    "                                                                  # if outcome was reached at t1, no further action required\n",
    "                                                                  noise)) \n",
    "    action2_blue_p = perturb(action2_blue_p)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_orange_p = pm.Deterministic(\"action2_orange_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,1)*(1-noise) + \\\n",
    "                                                                  # if belief both are needed and blue was pushed previously, then push orange \n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,0)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,0)*noise,\n",
    "                                                                  noise)) \n",
    "    action2_orange_p = perturb(action2_orange_p)\n",
    "    action2_stack = tt.transpose(tt.stack(action2_blue_p, action2_orange_p, [noise*2]))\n",
    "    action2 = pm.Categorical(\"action2\", action2_stack, observed=1, shape=(1)) # blue orange others\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace1d = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "unique, counts = np.unique(trace1d[\"world\"], return_counts=True)\n",
    "worldposterior_t4 = sort_category(unique, counts)\n",
    "rmse_output_t4 = rmse(worldposterior_t4, worldhuman_noemotion_t4)\n",
    "print(rmse_output_t4)\n",
    "unique, counts = np.unique(trace1[\"world\"], return_counts=True)\n",
    "worldposterior_t5 = sort_category(unique, counts)\n",
    "rmse_output_t5 = rmse(worldposterior_t5, worldhuman_noemotion_t5)\n",
    "print(rmse_output_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a762f-e205-4663-98aa-c0518f129e7f",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1ab[\"world_prior\"], return_counts=True)\n",
    "print(\"world t1: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t1 :\" + str(compute_ci_discrete(flatten(trace1ab[\"world_prior\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a29f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1ab[\"world\"], return_counts=True)\n",
    "print(\"world t2: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb981183",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t2 :\" + str(compute_ci_discrete(flatten(trace1ab[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1c[\"world\"], return_counts=True)\n",
    "print(\"world t3: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t3 :\" + str(compute_ci_discrete(flatten(trace1c[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1d[\"world\"], return_counts=True)\n",
    "print(\"world t4: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4651484",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t4 :\" + str(compute_ci_discrete(flatten(trace1d[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08011e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace1[\"world\"], return_counts=True)\n",
    "print(\"world t5: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85434b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t5 :\" + str(compute_ci_discrete(flatten(trace1[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38638d97",
   "metadata": {},
   "source": [
    "## Models (for the condition with emotional displays) across various snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model2ab:\n",
    "    noise = .15\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    world_prior = pm.Categorical(\"world_prior\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace2ab = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "\n",
    "unique, counts = np.unique(trace2ab[\"world_prior\"], return_counts=True)\n",
    "worldposterior_t1 = sort_category(unique, counts)\n",
    "rmse_output_t1 = rmse(worldposterior_t1, worldhuman_emotion_t1)\n",
    "print(rmse_output_t1)\n",
    "unique, counts = np.unique(trace2ab[\"world\"], return_counts=True)\n",
    "worldposterior_t2 = sort_category(unique, counts)\n",
    "rmse_output_t2 = rmse(worldposterior_t2, worldhuman_emotion_t2)\n",
    "print(rmse_output_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63460f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model2c:\n",
    "    noise = .15\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=1 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    draw = 2000 \n",
    "    trace2c = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "\n",
    "unique, counts = np.unique(trace2c[\"world\"], return_counts=True)\n",
    "worldposterior_t3 = sort_category(unique, counts)\n",
    "rmse_output_t3 = rmse(worldposterior_t3, worldhuman_emotion_t3)\n",
    "print(rmse_output_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "with pm.Model() as model2d:\n",
    "    noise = .15\n",
    "    world = pm.Categorical(\"world\", [human_prior], shape=(1)) # blue, orange, both\n",
    "    knowledge_p = pm.Beta(\"knowledge_p\", a, b, shape=(1)) # reliability of the agent's knowledge\n",
    "    knowledge = pm.Binomial(\"knowledge\", 1, knowledge_p, shape=(1))\n",
    "    \n",
    "    belief1_random = pm.Categorical(\"belief1_random\", [1,1,1], shape=(1))\n",
    "    belief1 = pm.Deterministic(\"belief1\", knowledge*world + (1-knowledge)*belief1_random)\n",
    "    \n",
    "    desire = pm.Binomial(\"desire\",1, d, shape=(1)) # bulb=1, others=0\n",
    "\n",
    "    action1_blue_p = pm.Deterministic(\"action1_blue_p\", tt.eq(belief1,0)*desire*(1-noise) + \\\n",
    "                                      # if believe both are needed,\n",
    "                                      tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                      # mistaken action\n",
    "                                      tt.eq(belief1,1)*desire*noise +\\\n",
    "                                      # if desire something else\n",
    "                                      (1-desire)*noise)\n",
    "    action1_blue_p = perturb(action1_blue_p)\n",
    "    \n",
    "    action1_orange_p = pm.Deterministic(\"action1_orange_p\", tt.eq(belief1,1)*desire*(1-noise) + \\\n",
    "                                        # if belief both are needed,\n",
    "                                        tt.eq(belief1,2)*desire*(1-noise) + \\\n",
    "                                        # mistaken action\n",
    "                                        tt.eq(belief1,0)*desire*noise +\\\n",
    "                                        # if desire something else,\n",
    "                                        (1-desire)*noise)\n",
    "    action1_orange_p = perturb(action1_orange_p)\n",
    "    \n",
    "    action1_stack = tt.transpose(tt.stack(action1_blue_p,action1_orange_p,[noise*2]))\n",
    "    action1 = pm.Categorical(\"action1\",action1_stack,observed=0,shape=(1)) # blue orange others\n",
    "    \n",
    "    outcome1_p = pm.Deterministic(\"outcome1_p\", tt.eq(world,0)*tt.eq(action1,0)*(1-delay) + \\\n",
    "                                  tt.eq(world,1)*tt.eq(action1,1)*(1-delay) + \\\n",
    "                                  # if both boxes are required, then outcome will not happen\n",
    "                                  tt.eq(world,2)*0)\n",
    "    outcome1_p = perturb(outcome1_p,noise) # add noise to outcome\n",
    "    \n",
    "    outcome1 = pm.Binomial(\"outcome1\", 1, outcome1_p, observed = 0 , shape = (1))\n",
    "    \n",
    "    happy1 = outcome1*desire*(1-noise) + noise*(1-desire)\n",
    "    # if agent believes both actions are needed, they won't be frustrated at the lack of an outcome\n",
    "    frustrated1 = (1-outcome1)*desire*tt.neq(belief1, 2)*(1-noise) + (1-outcome1)*desire*tt.eq(belief1, 2)*noise + noise*(1-desire)\n",
    "    neutral1 = [1]\n",
    "    emotion_array1 = tt.transpose(tt.stack(happy1, frustrated1, neutral1 ))\n",
    "    expression1 = pm.Categorical(\"expression1\",emotion_array1,observed=1 ) # happy, frustrated, neutral\n",
    "\n",
    "    # if frustrated, agent is likely to revise belief\n",
    "    # else stick to previous belief\n",
    "    belief2_random = pm.Categorical(\"belief2_random\", [1,1,1], shape=(1))\n",
    "    belief2 = pm.Deterministic(\"belief2\", tt.eq(expression1,1)*belief2_random + \\\n",
    "                              tt.neq(expression1,1)*belief1)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_blue_p = pm.Deterministic(\"action2_blue_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,0)*(1-noise) + \\\n",
    "                                                                  # if belief both are needed and orange was pushed previously, then push blue\n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,1)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,1)*noise,\n",
    "                                                                  # if outcome was reached at t1, no further action required\n",
    "                                                                  noise)) \n",
    "    action2_blue_p = perturb(action2_blue_p)\n",
    "    \n",
    "    # if outcome has been reached (and agent desired outcome), then likely no action would follow \n",
    "    action2_orange_p = pm.Deterministic(\"action2_orange_p\", tt.switch(tt.eq(outcome1,0)*desire, \\\n",
    "                                                                  tt.eq(belief2,1)*(1-noise) + \\\n",
    "                                                                  # if belief both are needed and blue was pushed previously, then push orange \n",
    "                                                                  tt.eq(belief2,2)*tt.eq(action1,0)*(1-noise)+ \\\n",
    "                                                                  # mistaken action\n",
    "                                                                  tt.eq(belief2,0)*noise,\n",
    "                                                                  noise)) \n",
    "    action2_orange_p = perturb(action2_orange_p)\n",
    "    action2_stack = tt.transpose(tt.stack(action2_blue_p, action2_orange_p, [noise*2]))\n",
    "    action2 = pm.Categorical(\"action2\", action2_stack, observed=1, shape=(1)) # blue orange \n",
    "    \n",
    "    draw = 2000 \n",
    "    trace2d = pm.sample(draw, tune=1000, chains=4, return_inferencedata=False)\n",
    "    \n",
    "unique, counts = np.unique(trace2d[\"world\"], return_counts=True)\n",
    "worldposterior_t4 = sort_category(unique, counts)\n",
    "rmse_output_t4 = rmse(worldposterior_t4, worldhuman_emotion_t4)\n",
    "print(rmse_output_t4)\n",
    "unique, counts = np.unique(trace2[\"world\"], return_counts=True)\n",
    "worldposterior_t5 = sort_category(unique, counts)\n",
    "rmse_output_t5 = rmse(worldposterior_t5, worldhuman_emotion_t5)\n",
    "print(rmse_output_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd33adb-3887-455f-9c84-800feff6ce99",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34826269",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2ab[\"world_prior\"], return_counts=True)\n",
    "print(\"world t1: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1183a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t1 :\" + str(compute_ci_discrete(flatten(trace2ab[\"world_prior\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399624fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2ab[\"world\"], return_counts=True)\n",
    "print(\"world t2: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4deb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t2 :\" + str(compute_ci_discrete(flatten(trace2ab[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2c[\"world\"], return_counts=True)\n",
    "print(\"world t3: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t3 :\" + str(compute_ci_discrete(flatten(trace2c[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2d[\"world\"], return_counts=True)\n",
    "print(\"world t4: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t4 :\" + str(compute_ci_discrete(flatten(trace2d[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(trace2[\"world\"], return_counts=True)\n",
    "print(\"world t5: \" + str(dict(zip(unique, counts))))\n",
    "print(sort_category(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2be027",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "print(\"world t5 :\" + str(compute_ci_discrete(flatten(trace2[\"world\"]), HDI = .95, n = 1000, sim = 1000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
